import snscrape.modules.twitter as sntwitter
import datetime

# --- ç¬¬ä¸€é˜¶æ®µï¼šæ–°å¢çš„é…ç½®é¡¹ ---

# 1. å‘å¸ƒè€…ç¡¬æŒ‡æ ‡ç­›é€‰é˜ˆå€¼
MIN_FOLLOWER_COUNT = 1000  # ç”¨æˆ·çš„æœ€ä½ç²‰ä¸æ•°
MIN_ACCOUNT_AGE_DAYS = 180 # è´¦æˆ·çš„æœ€çŸ­æ³¨å†Œå¤©æ•° (çº¦6ä¸ªæœˆ)

# 2. å…³é”®è¯æœç´¢çš„é€šç”¨è¿‡æ»¤æŒ‡ä»¤ (ä¼šè‡ªåŠ¨é™„åŠ åˆ°æ¯ä¸ªå…³é”®è¯åé¢)
KEYWORD_FILTERS = "min_faves:10 lang:en" # è‡³å°‘10ä¸ªç‚¹èµï¼Œä¸”è¯­è¨€ä¸ºè‹±æ–‡

# 3. ç›‘æ§ç›®æ ‡åˆ—è¡¨
KOL_ACCOUNTS = [
    "VitalikButerin", "saylor", "a16zcrypto", "arthurhayes", "elonmusk",
    "woonomic", "lookonchain", "realDonaldTrump",
]

KEYWORDS_TO_TRACK = [
    "RWA", "DePIN", "AI crypto", "Restaking", "airdrop", "$SOL", "$TON",
]

# 4. æ¯ä¸ªæŸ¥è¯¢çš„æŠ“å–æ•°é‡ä¸Šé™
LIMIT_PER_QUERY = 10 # é€‚å½“å¢åŠ ä¸Šé™ï¼Œå› ä¸ºå¾ˆå¤šä¼šè¢«è¿‡æ»¤æ‰

def scrape_social_media_feeds():
    """
    ä½¿ç”¨snscrapeæŠ“å–ä¿¡æ¯ï¼Œå¹¶åº”ç”¨ç¬¬ä¸€é˜¶æ®µçš„è¿‡æ»¤è§„åˆ™ã€‚
    """
    print("ğŸ”„ [ç¬¬ä¸€é˜¶æ®µ] å¯åŠ¨ç¤¾äº¤åª’ä½“ä¿¡æ¯æŠ“å– (å·²å¼€å¯é¢„è¿‡æ»¤)...")
    all_posts = []
    
    # --- æŠ“å–KOLçš„æ¨æ–‡ (ä¸è¿›è¡Œé¢å¤–è¿‡æ»¤) ---
    print(f"ğŸ¤ æ­£åœ¨æŠ“å– {len(KOL_ACCOUNTS)} ä½æ ¸å¿ƒKOLçš„æ¨æ–‡...")
    for username in KOL_ACCOUNTS:
        try:
            scraper = sntwitter.TwitterUserScraper(username)
            for i, tweet in enumerate(scraper.get_items()):
                if i >= LIMIT_PER_QUERY:
                    break
                all_posts.append(f"æ¥è‡ªæ ¸å¿ƒKOL {username} çš„æ¨æ–‡: {tweet.rawContent}")
        except Exception as e:
            print(f"âŒ æŠ“å–ç”¨æˆ· {username} æ—¶å‡ºé”™: {e}")

    # --- æŠ“å–å…³é”®è¯ç›¸å…³çš„æ¨æ–‡ (åº”ç”¨ç¡¬æŒ‡æ ‡è¿‡æ»¤) ---
    print(f"ğŸ” æ­£åœ¨æŠ“å– {len(KEYWORDS_TO_TRACK)} ä¸ªå…³é”®è¯çš„è®¨è®º (å°†è¿›è¡Œä¸¥æ ¼ç­›é€‰)...")
    # è·å–å½“å‰çš„UTCæ—¶é—´ï¼Œç”¨äºè®¡ç®—è´¦æˆ·å¹´é¾„
    now = datetime.datetime.now(datetime.timezone.utc)

    for keyword in KEYWORDS_TO_TRACK:
        # æ„é€ å¸¦æœ‰é«˜çº§è¿‡æ»¤æŒ‡ä»¤çš„æœç´¢æŸ¥è¯¢
        advanced_query = f'"{keyword}" {KEYWORD_FILTERS}'
        print(f"  -> æ­£åœ¨æœç´¢: {advanced_query}")
        try:
            scraper = sntwitter.TwitterSearchScraper(advanced_query)
            for i, tweet in enumerate(scraper.get_items()):
                if i >= (LIMIT_PER_QUERY * 5): # æ‰©å¤§æœç´¢èŒƒå›´ï¼Œå› ä¸ºå¾ˆå¤šä¼šè¢«è¿‡æ»¤
                    break
                
                # --- [æ ¸å¿ƒè¿‡æ»¤é€»è¾‘] ---
                # 1. ç­›é€‰è´¦æˆ·å¹´é¾„
                account_age_days = (now - tweet.user.created).days
                if account_age_days < MIN_ACCOUNT_AGE_DAYS:
                    # print(f"  -> è¿‡æ»¤: ä½œè€…({tweet.user.username})æ³¨å†Œæ—¶é—´({account_age_days}å¤©)è¿‡çŸ­ã€‚")
                    continue # è·³è¿‡è¿™æ¡æ¨æ–‡

                # 2. ç­›é€‰ç²‰ä¸æ•°
                if tweet.user.followersCount < MIN_FOLLOWER_COUNT:
                    # print(f"  -> è¿‡æ»¤: ä½œè€…({tweet.user.username})ç²‰ä¸æ•°({tweet.user.followersCount})è¿‡ä½ã€‚")
                    continue # è·³è¿‡è¿™æ¡æ¨æ–‡
                
                # å¦‚æœé€šè¿‡æ‰€æœ‰ç­›é€‰ï¼Œåˆ™é‡‡çº³è¯¥ä¿¡æ¯
                all_posts.append(f"å…³äº'{keyword}'çš„é«˜è´¨é‡è®¨è®º: {tweet.rawContent}")

                # é™åˆ¶æ¯ä¸ªå…³é”®è¯æœ€ç»ˆåªé‡‡çº³å‡ æ¡é«˜è´¨é‡ä¿¡æ¯
                if len([p for p in all_posts if f"'{keyword}'" in p]) >= LIMIT_PER_QUERY:
                    break

        except Exception as e:
            print(f"âŒ æŠ“å–å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {e}")
    
    if all_posts:
        print(f"âœ… [ç¬¬ä¸€é˜¶æ®µ] è¿‡æ»¤å®Œæˆï¼ŒæˆåŠŸæ•è· {len(all_posts)} æ¡é«˜è´¨é‡åŠ¨æ€ã€‚")
    else:
        print("âš ï¸ [ç¬¬ä¸€é˜¶æ®µ] æœªæ•è·åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„é«˜è´¨é‡ä¿¡æ¯ã€‚")
            
    return all_posts

# --- æµ‹è¯•æ¨¡å— ---
if __name__ == '__main__':
    latest_posts = scrape_social_media_feeds()
    if latest_posts:
        print("\n--- [ç¬¬ä¸€é˜¶æ®µ] ç­›é€‰åçš„é«˜è´¨é‡åŠ¨æ€é¢„è§ˆ ---")
        for post in latest_posts:
            print(f"- {post[:150]}...")